{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWzslMs5a0zf",
    "outputId": "60505474-ec67-4a19-91d0-28b62625ee79"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoRxWqPwgZxU"
   },
   "source": [
    "# Run this block once and then reload\n",
    "## No need to run after reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yUsDCTIK2En1",
    "outputId": "1ac68ec0-b3c0-46d8-ef39-149c000f6b67"
   },
   "outputs": [],
   "source": [
    "# Run once and reload\n",
    "# # No need to run after reloading\n",
    "# !pip install torchdyn\n",
    "# !pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pOWFq11yaJnz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9fade73de95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msolve_ivp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.integrate import solve_ivp\n",
    "from torch.optim import AdamW\n",
    "from torchdyn.core import ODEProblem\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Tcyiaz2ag68"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "  torch.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmSPd6ijah8e"
   },
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWedIY3igomy"
   },
   "source": [
    "# Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olD_YuIaaQZO"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "###################################\n",
    "# Argments\n",
    "IS_RESTART = False\n",
    "P_CUTOFF = 0.0\n",
    "N_EPOCH = 1000000\n",
    "N_PLOT = 100\n",
    "DATASIZE = 100\n",
    "TSTEP = 0.4\n",
    "N_EXP_TRAIN = 20\n",
    "N_EXP_TEST = 10\n",
    "N_EXP = N_EXP_TRAIN + N_EXP_TEST\n",
    "NOISE = 5.0e-2\n",
    "NS = 5\n",
    "NR = 4\n",
    "K = torch.tensor([0.1, 0.2, 0.13, 0.3])\n",
    "ATOL = 1e-5\n",
    "RTOL = 1e-2\n",
    "\n",
    "MAXITERS = 10000\n",
    "\n",
    "LB = 1.0e-5\n",
    "UB = 1.0e1\n",
    "\n",
    "B0 = -10\n",
    "\n",
    "####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgRFWS5Zg0tS"
   },
   "source": [
    "# Directories to store checkpoints and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iSKDiZ0gyhq"
   },
   "outputs": [],
   "source": [
    "# Make sure to not put a '/' after the folder name\n",
    "BASE_DIR = '/content/drive/MyDrive/CRNN'\n",
    "SAVE_EXP_DIR = \"figs_py\"  \n",
    "CHECKPOINT_DIR= \"checkpoint\"\n",
    "CHECKPOINT_SAVE_PATH = f\"{BASE_DIR}/{CHECKPOINT_DIR}/mymodel.pt\" \n",
    "LOSS_SAVE_PATH = f\"{BASE_DIR}/{SAVE_EXP_DIR}/loss.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxzQ4-t6AHaq"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(BASE_DIR) == False:\n",
    "  os.mkdir(BASE_DIR)\n",
    "if os.path.exists(f'{BASE_DIR}/{SAVE_EXP_DIR}') == False:\n",
    "  os.mkdir(f'{BASE_DIR}/{SAVE_EXP_DIR}')\n",
    "if os.path.exists(f'{BASE_DIR}/{CHECKPOINT_DIR}') == False:\n",
    "  os.mkdir(f'{BASE_DIR}/{CHECKPOINT_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "354vI9WGZah0"
   },
   "outputs": [],
   "source": [
    "def trueODEfunc(t, y, k):\n",
    "  dydt_0 = -2 * k[0] * y[0] ** 2 - k[1] * y[0]\n",
    "  dydt_1 = k[0] * y[0] ** 2 - k[3] * y[1] * y[3]\n",
    "  dydt_2 = k[1] * y[0] - k[2] * y[2]\n",
    "  dydt_3 = k[2] * y[2] - k[3] * y[1] * y[3]\n",
    "  dydt_4 = k[3] * y[1] * y[3]\n",
    "  return [dydt_0, dydt_1, dydt_2, dydt_3, dydt_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awH83GimrfAD"
   },
   "outputs": [],
   "source": [
    "def max_min(ode_data):\n",
    "  return torch.amax(ode_data, dim=1) - torch.amin(ode_data, dim=1) + LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCjrrfDpriEi"
   },
   "outputs": [],
   "source": [
    "def p2vec(p):\n",
    "    w_b = p[:NR] + B0\n",
    "    w_out = torch.reshape(p[NR:], (NR, NS)).transpose(0, 1)\n",
    "    w_in = torch.clamp(-w_out, 0, 2.5)\n",
    "    return w_in, w_b, w_out\n",
    "\n",
    "\n",
    "def display_p(p):\n",
    "    w_in, w_b, w_out = p2vec(p)\n",
    "    print(\"species (column) reaction (row)\")\n",
    "    print(\"w_in\")\n",
    "    print(w_in.transpose(0, 1))\n",
    "    print(\"\\nw_b\")\n",
    "    print(w_b)\n",
    "    print(\"\\nw_out\")\n",
    "    print(w_out.transpose(0, 1))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYfS_9zvtsMo"
   },
   "outputs": [],
   "source": [
    "class CRNN(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.p = torch.nn.Parameter(torch.randn(NR * (NS + 1)) * 1.0e-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        w_in, w_b, w_out = self._p2vec()\n",
    "        w_in_x = w_in.transpose(0, 1) @ torch.log(torch.clamp(x, min=LB, max=UB))\n",
    "        return w_out @ torch.exp(w_in_x + w_b)\n",
    "\n",
    "    def _p2vec(self):\n",
    "        w_b = self.p[:NR] + B0\n",
    "        w_out = torch.reshape(self.p[NR:], (NR, NS)).transpose(0, 1)\n",
    "        w_in = torch.clamp(-w_out, 0, 2.5)\n",
    "        return w_in, w_b, w_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DBVuuxHtwym"
   },
   "outputs": [],
   "source": [
    "def plot_losses(list_loss_train, list_loss_test):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.7), layout=\"constrained\")\n",
    "    ax.plot(list_loss_train, label=\"train\")\n",
    "    ax.plot(list_loss_test, label=\"val\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.grid(True)\n",
    "    ax.set_title(\"Loss Plots\")  # Add a title to the axes.\n",
    "    ax.legend()\n",
    "    # Add a legend.\n",
    "    fig.savefig(LOSS_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhMjuJpktwv1"
   },
   "outputs": [],
   "source": [
    "def plot_exps(tsteps, ode_data_list, pred, i_exp):\n",
    "    species = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "    ncols = NS - int(NS / 2)\n",
    "    nrows = int(NS / 2)\n",
    "    fig, axs = plt.subplots(\n",
    "        ncols=ncols, nrows=nrows, figsize=(20.5, 12.5), layout=\"constrained\"\n",
    "    )\n",
    "\n",
    "    ode_index = 0\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            if ode_index == NS:\n",
    "                break\n",
    "            ode_data = ode_data_list[i_exp, ode_index, :]\n",
    "            axs[row, col].scatter(tsteps, ode_data, label=\"Exp\", c=\"orange\", marker=\"x\")\n",
    "            axs[row, col].plot(tsteps, pred[ode_index], label=\"CRNN-ODE\")\n",
    "            axs[row, col].set_xlabel(\"Time\")\n",
    "            axs[row, col].set_ylabel(f\"Concentration of {species[ode_index]}\")\n",
    "\n",
    "            if ode_index == 0:\n",
    "                axs[row, col].legend()\n",
    "\n",
    "            if row == 1 and col == 2:\n",
    "                axs[row, col].get_xaxis().set_visible(False)\n",
    "                axs[row, col].get_yaxis().set_visible(False)\n",
    "\n",
    "            ode_index += 1\n",
    "\n",
    "    fig.savefig(f\"{BASE_DIR}/{SAVE_EXP_DIR}/i_exp_{i_exp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-Tt_LfcvciY"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed_everything()\n",
    "\n",
    "\n",
    "\n",
    "    # Generate Datasets\n",
    "    u0_list = torch.rand((N_EXP, NS)).reshape((NS, N_EXP)).transpose(0, 1)\n",
    "    u0_list[:, 0:2] += 2.0e-1\n",
    "    u0_list[:, 2:] = 0.0\n",
    "    tspan = torch.tensor([0.0, DATASIZE * TSTEP])\n",
    "    tsteps = torch.linspace(tspan[0], tspan[1], DATASIZE)\n",
    "    ode_data_list = torch.zeros((N_EXP, NS, DATASIZE))\n",
    "    std_list = torch.tensor([])\n",
    "\n",
    "    # # push ode data to std list\n",
    "    # print(\"Calculating y_std...\")\n",
    "    # for i in range(N_EXP):\n",
    "    #     u0 = u0_list[i]\n",
    "    #     ode_data = solve_ivp(\n",
    "    #         trueODEfunc,\n",
    "    #         tspan.numpy(),\n",
    "    #         u0.numpy(),\n",
    "    #         t_eval=tsteps.numpy(),\n",
    "    #         args=(K.numpy(),),\n",
    "    #     )\n",
    "    #     ode_data = ode_data.y\n",
    "    #     ode_data = torch.tensor(ode_data)\n",
    "    #     # The reshape and the transpose makes the alignment same with julia\n",
    "    #     ode_data += (\n",
    "    #         torch.rand((ode_data.shape))\n",
    "    #         .reshape((ode_data.shape[1], -1))\n",
    "    #         .transpose(0, 1)\n",
    "    #         * ode_data\n",
    "    #         * NOISE\n",
    "    #     )\n",
    "    #     ode_data_list[i] = ode_data\n",
    "    #     std_list = torch.cat((std_list, ode_data.unsqueeze(dim=0)))\n",
    "\n",
    "\n",
    "    #Data Processed Here from CSV\n",
    "    print(\"Reading csv files...\")\n",
    "    data = []\n",
    "    colnames = [str(i) for i in range(100)]\n",
    "    for i in range(1, 31):\n",
    "        df = pd.read_csv(\"./CRNN/case1/csv/\" + str(i) + \".csv\", names=colnames)\n",
    "        # print(df)\n",
    "        ode_data_np = df.to_numpy()\n",
    "        data.append(ode_data_np)\n",
    "        ode_data_pt = torch.tensor(ode_data_np)\n",
    "        ode_data_list[i-1] = ode_data_pt\n",
    "        std_list = torch.cat((std_list, max_min(ode_data_pt).unsqueeze(dim=0)))\n",
    "\n",
    "    print(\"Calculating y_std...\")\n",
    "    y_std = torch.amax(std_list, dim=0)\n",
    "    print(std_list.shape)\n",
    "    print(f\"y_std: \\t{y_std}\")\n",
    "\n",
    "    u0 = u0_list[0]\n",
    "    p = torch.randn(NR * (NS + 1)) * 1.0e-1\n",
    "\n",
    "    model = CRNN()\n",
    "    model_prob = ODEProblem(model, solver=\"tsit5\", atol=ATOL, rtol=RTOL).to(device)\n",
    "\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    optimizer = AdamW(model_prob.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1.0e-8)\n",
    "\n",
    "    epoch_start = 0\n",
    "    if IS_RESTART:\n",
    "        checkpoint = torch.load(CHECKPOINT_SAVE_PATH)\n",
    "        model_prob.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        epoch_start = checkpoint[\"epoch\"]\n",
    "        loss_train = checkpoint[\"loss_train\"]\n",
    "        loss_test = checkpoint[\"loss_test\"]\n",
    "\n",
    "    list_loss_train = []\n",
    "    list_loss_test = []\n",
    "\n",
    "    tsteps = tsteps.to(device)\n",
    "    ode_data_list = ode_data_list.to(device)\n",
    "    y_std = y_std.to(device)\n",
    "\n",
    "    for num_iter, epoch in enumerate(tqdm(range(epoch_start, N_EPOCH))):\n",
    "        loss_epoch = torch.zeros(N_EXP).to(device)\n",
    "\n",
    "        model_prob.train()\n",
    "        for i_exp in torch.randperm(N_EXP_TRAIN):\n",
    "            u_train = u0_list[i_exp].to(device)\n",
    "            t_train, y_hat = model_prob(u_train, tsteps)\n",
    "            y_hat = y_hat.transpose(0, 1)\n",
    "            # print(\"yhat shape: \", y_hat.shape)\n",
    "            # print(\"ode_data_list shape: \", ode_data_list.shape)\n",
    "            # y_hat = torch.transpose(y_hat, 0, 1)\n",
    "            ode = ode_data_list[i_exp]\n",
    "            # print(\"ode shape: \", ode.shape)\n",
    "            # y_std = torch.transpose(y_std, 0, 1)\n",
    "            # print(\"y_std shape: \", y_std.view(5, 1))\n",
    "\n",
    "\n",
    "            loss = criterion(ode / y_std.view(5, 1), y_hat / y_std.view(5,1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_epoch[i_exp] = loss\n",
    "\n",
    "        model_prob.eval()\n",
    "        for i_exp_eval in range(N_EXP_TRAIN, N_EXP):\n",
    "            u_eval = u0_list[i_exp_eval].to(device)\n",
    "            t_eval, y_hat_eval = model_prob(u_eval, tsteps)\n",
    "            y_hat_eval = y_hat_eval.transpose(0, 1)\n",
    "            ode = ode_data_list[i_exp_eval]\n",
    "\n",
    "            loss_eval = criterion(ode / y_std.view(5,1), y_hat_eval / y_std.view(5,1))\n",
    "            loss_epoch[i_exp_eval] = loss_eval\n",
    "\n",
    "        loss_train = torch.mean(loss_epoch[:N_EXP_TRAIN])\n",
    "        loss_test = torch.mean(loss_epoch[N_EXP_TRAIN:])\n",
    "\n",
    "        print(f\"\\nLoss Train: \\t{loss_train.item()}\")\n",
    "        print(f\"Loss Test: \\t{loss_test.item()}\")\n",
    "\n",
    "        list_loss_train.append(loss_train.item())\n",
    "        list_loss_test.append(loss_test.item())\n",
    "\n",
    "        if num_iter % N_PLOT == 0:\n",
    "            display_p(next(model_prob.parameters()).cpu().detach())\n",
    "\n",
    "            print(f\"Minimum Loss Train: \\t{min(list_loss_train)}\")\n",
    "            print(f\"Minimum Loss Test: \\t{min(list_loss_test)}\")\n",
    "\n",
    "            # Plot exp figures\n",
    "            i_exp = np.random.permutation(N_EXP)[0]\n",
    "            model_prob.eval()\n",
    "            i_exp_data = u0_list[i_exp].to(device)\n",
    "            _, y_hat_exp = model_prob(i_exp_data, tsteps)\n",
    "            y_hat_exp = y_hat_exp.transpose(0, 1)\n",
    "            # plot_exps(tsteps, ode_data_list, y_hat_exp.detach().numpy(), i_exp)\n",
    "            plot_exps(\n",
    "                tsteps.cpu().numpy(),\n",
    "                ode_data_list.cpu().numpy(),\n",
    "                y_hat_exp.detach().cpu().numpy(),\n",
    "                i_exp,\n",
    "            )\n",
    "\n",
    "            # Save loss\n",
    "            plot_losses(list_loss_train, list_loss_test)\n",
    "\n",
    "            # Save checkpoint\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model_prob.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"loss_train\": loss_train.item(),\n",
    "                    \"loss_test\": loss_test.item(),\n",
    "                },\n",
    "                CHECKPOINT_SAVE_PATH,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lH5Rkd9rtwqZ",
    "outputId": "9648aeda-110a-471c-91b7-1bb9405898e7"
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeUJbqszpfif"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
